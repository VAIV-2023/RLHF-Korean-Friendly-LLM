2023 ì„±ê· ê´€ëŒ€ í•˜ê³„ì§‘ì¤‘ ì‚°í•™í˜‘ë ¥í”„ë¡œì íŠ¸ VAIV
## GPT ê¸°ë°˜ì˜ ìì—°ìŠ¤ëŸ½ê³ (Friendly) ìœ¤ë¦¬ì ì¸(Harmless) ì¼ìƒ ëŒ€í™”í˜• ì±—ë´‡ ëª¨ë¸

#  ì—°êµ¬ ë°°ê²½ ë° ëª©ì 
    GPT-NEOX(Polyglot-ko) ê¸°ë°˜ ìì—°ìŠ¤ëŸ½ê³  ìœ¤ë¦¬ì ì¸ í•œêµ­ì–´ ê¸°ë°˜ ì¼ìƒ ëŒ€í™”í˜• ì±—ë´‡ ëª¨ë¸ êµ¬í˜„
![image](https://github.com/VAIV-2023/RLHF-Korean-Friendly-LLM/assets/79634774/18bb1ab4-8924-4b43-b538-1e6529297217)
  
# ê°œë°œ ë‚´ìš©
- Self-Instruct: GPT4ë¥¼ ì´ìš©í•œ ë°ì´í„° ì¦ê°•
- RLHF(Reinforcement Learning from Human Feedback): ì‚¬ëŒì˜ ì„ í˜¸ë„ë¥¼ ë°˜ì˜í•œ ê°•í™”í•™ìŠµ
- DeepSpeed: ëŒ€ê·œëª¨ ë¶„ì‚° ë”¥ëŸ¬ë‹ì„ ìœ„í•œ ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ ìµœì í™” ê¸°ìˆ 

    - Task 1: ê°•í™”í•™ìŠµ ë‹¨ê³„ë³„ ë°ì´í„°ì…‹ êµ¬ì¶•
    - Task 2: SFT ëª¨ë¸ Instruction-tuning
    - Task 3: Reward ëª¨ë¸ ver1,2,3 êµ¬í˜„
    - Task 4: RLHFì™€ DeepSpeedChatì„ í†µí•œ ìµœì¢… ëª¨ë¸ êµ¬í˜„ (https://huggingface.co/Trofish/KULLM-RLHF)

# Task1. ê°•í™”í•™ìŠµ ë‹¨ê³„ë³„ ë°ì´í„°ì…‹ êµ¬ì¶•
![image](https://github.com/VAIV-2023/RLHF-Korean-Friendly-LLM/assets/79634774/4bb56e36-0c49-4d15-a2c6-2824867419a8)

## Source

### ì¼ìƒëŒ€í™” ë°ì´í„°ì…‹
- **ì¶œì²˜:** êµ­ë¦½êµ­ì–´ì› ëª¨ë‘ì˜ ë§ë­‰ì¹˜ ì¼ìƒ ëŒ€í™” ë°ì´í„°ì…‹
- **URL:** [ëª¨ë‘ì˜ ë§ë­‰ì¹˜ ì¼ìƒ ëŒ€í™” ë°ì´í„°ì…‹](https://corpus.korean.go.kr/request/reausetMain.do?lang=ko)

### í˜ì˜¤í‘œí˜„ ë°ì´í„°ì…‹
- **ì¶œì²˜:** AIHub í…ìŠ¤íŠ¸ ìœ¤ë¦¬ ê²€ì¦ ë°ì´í„°ì…‹
- **URL:** [AIHub í…ìŠ¤íŠ¸ ìœ¤ë¦¬ ê²€ì¦ ë°ì´í„°ì…‹](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=558)

### RLHF ë²ˆì—­ ë°ì´í„°ì…‹
- **ì¶œì²˜:** Step 2 Reward ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ë°ì´í„°ì…‹ (DeepSpeedChatì—ì„œ ê³µê°œ)
- **URL:** [RLHF Reward Datasets](https://huggingface.co/datasets/yitingxie/rlhf-reward-datasets)

### Self-Instruct ë°ì´í„°ì…‹
- **Evol-instruct:**
  - **ì„¤ëª…:** ë‹¤ì–‘í•œ ë¶„ì•¼ì— ëŒ€í•œ ë³µì¡í•˜ê³  ë…¼ë¦¬ì ì¸ promptì™€ ë‹µë³€ì´ í¬í•¨ëœ ë°ì´í„°ì…‹
  - **URL:** [Evol-instruct](https://github.com/lcw99/evolve-instruct/)

- **Self-Instruct:**
  - **ì„¤ëª…:** ì‚¬ëŒì´ ì§ì ‘ ìƒì„±í•œ ì–‘ì§ˆì˜ Seed dataë¥¼ ê¸°ë°˜ìœ¼ë¡œ GPT-3.5ë¥¼ ì´ìš©í•´ Self ë°ì´í„° ì¦ê°•

### KoBEST ë°ì´í„°ì…‹
- **ì¶œì²˜:** í‰ê°€ìš©ìœ¼ë¡œ Commonsense & Inference ëŠ¥ë ¥ê³¼ ê´€ë ¨ëœ KoBEST ä¸­ COPA, HellaSwag ë°ì´í„°ì…‹ 
- **URL:** [KoBEST ë°ì´í„°ì…‹](https://huggingface.co/datasets/skt/kobest_v1/viewer/hellaswag/test)


# Task2. SFT ëª¨ë¸ Fine-tuning
## Baseline Model
[- ê³ ë ¤ëŒ€í•™êµ NLP & AI ì—°êµ¬ì‹¤ê³¼ HIAI ì—°êµ¬ì†Œê°€ ê°œë°œí•œ í•œêµ­ì–´ LLM **"KULLM"** ì‚¬ìš©](https://github.com/nlpai-lab/KULLM)

## Datasets
![image](https://github.com/VAIV-2023/VAIV2023/assets/79634774/085610db-3714-43c3-855b-58baad2f4e8b)

## SFT Model Finetuning 
![image](https://github.com/VAIV-2023/VAIV2023/assets/79634774/0f5e36fa-20a8-43f9-bd03-5f8224d5e9d0)
* ëª¨ë¸í•™ìŠµì—ëŠ” Google Colabì—ì„œ ì œê³µí•˜ëŠ” A100 40GB GPU ì‚¬ìš©
  
## SFT Model Evaluation
![image](https://github.com/VAIV-2023/VAIV2023/assets/79634774/9fe9e5aa-6dc7-4c7b-8529-45e0a75db9c6)
![image](https://github.com/VAIV-2023/VAIV2023/assets/79634774/a994a960-db7c-4e75-a11a-d7755d372722)
* G-Eval: https://arxiv.org/abs/2303.16634


# Task3-1. Reward Model ver1 êµ¬í˜„
## Baseline Model
- EleutherAIì—ì„œ ê°œë°œí•œ ì´ˆê±°ëŒ€ í•œêµ­ì–´ ì–¸ì–´ ëª¨ë¸ **Polyglot-Ko** ì‚¬ìš©
- 1.3b ëª¨ë¸ê³¼ 5.8b ëª¨ë¸ì„ ê°ê° ì‹¤í—˜
## Datasets
![image](https://github.com/VAIV-2023/RLHF-Korean-Friendly-LLM/assets/79634774/0082da9b-b0b8-4089-8647-cffa5ce724fb)
- InstructGPTì˜ ë°ì´í„°ì…‹ êµ¬ì¶• ë°©ë²•
    - Reward ëª¨ë¸ í•™ìŠµ ë°ì´í„°ì…‹ìœ¼ë¡œ SFT í•™ìŠµì— ì‚¬ìš©í•œ prompt(1,500ê°œ - ì¼ìƒëŒ€í™”:í˜ì˜¤í‘œí˜„=2:1)ì™€ ìƒˆë¡œìš´ prompt(1,000ê°œ - DeepSpeedChat ë²ˆì—­ ë°ì´í„°ì…‹) ì‚¬ìš© 
    - SFT ëª¨ë¸ì—ì„œ í•œê°œì˜ promptë‹¹ Kê°œì˜ Responseë¥¼ ìƒì„±í•˜ê³ , ìˆœìœ„ë¥¼ Labeling
- ë°ì´í„°ì…‹ ë¼ë²¨ë§
    - Instruct GPTì˜ ê²½ìš° ì‚¬ëŒì´ ì§ì ‘ Labelingì„ í•˜ì—¿ì§€ë§Œ, ì¼ê´€ëœ í‰ê°€ì™€ ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´ GPt-4ì™€ G-Evalì„ ì´ìš©
    - SFTì—ì„œ ìƒì„±í•œ ë‘ Response ì¤‘ G-Eval í‰ê°€ ì ìˆ˜ í•©ì´ ë†’ì€ ê²ƒì„ Chosen responseë¡œ ê²°ì •
    - ë°ì´í„°ì…‹ ìœ í˜•ë³„ë¡œ G-Eval í‰ê°€ Promptì— ì°¨ì´ë¥¼ ë‘ì—ˆìŒ
    -   ![image](https://github.com/VAIV-2023/RLHF-Korean-Friendly-LLM/assets/79634774/7d7117d0-02e9-42dd-8ce3-5244cf726bf8)
## Reward v1 Model Finetuning
- ![image](https://github.com/VAIV-2023/RLHF-Korean-Friendly-LLM/assets/79634774/da4d9b15-ec91-44bb-84d9-f28aeffd16ad)
- InstructGPT ë…¼ë¬¸ì— ë”°ë¥´ë©´, Reward ëª¨ë¸ì€ overfittingë˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ëœë‹¤ê³  í•¨ --> epoch ìˆ˜ë¥¼ 1ë¡œ ì„¤ì •
- batch sizeë‚˜ learning rate ë“± ë‹¤ë¥¸ hyper-parameterëŠ” ì„±ëŠ¥ì— í° ì˜í–¥ì´ ì—†ë‹¤ê³  í•¨
- Colab A100 40GB ê¸°ì¤€ ì´ í•™ìŠµ ì‹œê°„ 4ë¶„

## Reward v1 Model Evaluation
- ![image](https://github.com/VAIV-2023/RLHF-Korean-Friendly-LLM/assets/79634774/f4af0b7d-af47-4881-8adf-d14be43c0eb1)
- Reward Model Template
  - **"ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”. \n\n ### ëª…ë ¹ì–´:\n{prompt}\n\n ### ì‘ë‹µ:\n"**

# Task3-2. Reward Model ver2,3 êµ¬í˜„
## RewardModel ver1 Issues
- êµ¬í˜„ëœ Reward ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•ŠìŒ (Accuracy 0.65)
- Reward ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ Step3 í•™ìŠµì‹œ í˜ì˜¤í‘œí˜„ì´ ì•„ë‹Œë°ë„ í˜ì˜¤í‘œí˜„ì´ë¼ê³  ì¸ì‹í•˜ê³  ë‹µë³€í•˜ëŠ” ë¬¸ì œ ë°œìƒ

## Issue í•´ê²°ë°©ì•ˆ (Reward Model ver2,3)
- ![image](https://github.com/VAIV-2023/RLHF-Korean-Friendly-LLM/assets/79634774/99c7fd6c-448e-4780-9573-0ef51b8e3183)
- General Task ë‹µë³€ì— ëŒ€í•œ í‰ê°€ ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•´ Evol-instruct ë°ì´í„° ì¶”ê°€
- SFT ëª¨ë¸ë¡œ ë‹µë³€ì„ 2ê°œ ìƒì„±í•˜ì˜€ì„ ë•Œ, Chosen, Rejected ë‹µë³€ì˜ ì°¨ì´ê°€ í¬ê²Œ ì—†ì–´ ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•ŠëŠ” í˜„ìƒì„ ë°©ì§€í•˜ê¸° ìœ„í•˜ì—¬ 2ê°œì˜ ëª¨ë¸ **(ChatGPT, SFT)**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±
- í˜ì˜¤í‘œí˜„ í•™ìŠµì‹œ(Ver2) Step3 í•™ìŠµ ì´í›„ì— ë‹µë³€ì´ ì´ìƒí•˜ê²Œ ìƒì„±ë˜ëŠ” Issueê°€ ìˆì–´, í˜ì˜¤í‘œí˜„ì„ ë°ì´í„°ë¥¼ ì œê±°í•˜ê³  í•™ìŠµ(Ver3)
- RM-ver1ì€ GPT4ê°€ Chosen, Rejected ë ˆì´ë¸”ë§ì„ ì§„í–‰í•˜ì˜€ì§€ë§Œ, Resource ì´ìŠˆë¡œ ì¸í•´ ì¼ë¶€ë§Œ ì‚¬ëŒì´ ë¼ë²¨ë§ ì§„í–‰
    - ì¼ìƒëŒ€í™”, í˜ì˜¤í‘œí˜„ ë°ì´í„°ì…‹
        - ChatGPTì™€ SFT ëª¨ë‘ ì¼ê´€ë˜ê²Œ ë†’ì€ í€„ë¦¬í‹°ì˜ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ì•Šì•„, ì‚¬ëŒì´ ì§ì ‘ ë¼ë²¨ë§ ì§„í–‰
    - RLHF í•œêµ­ì–´ ë²ˆì—­, Evol-Instruct ë°ì´í„°ì…‹
        - ChatGPTê°€ ì¼ê´€ë˜ê²Œ ë†’ì€ í€„ë¦¬í‹°ì˜ ë‹µë³€ì„ ìƒì„±í•˜ì—¬ ChatGPTë¥¼ Chosen, SFTë¥¼ Rejectedë¡œ ë¼ë²¨ë§ ì§„   
## Reward Model ver2,3 Evaluation
![image](https://github.com/VAIV-2023/RLHF-Korean-Friendly-LLM/assets/79634774/7889398a-86dc-4b03-8300-64b772d49887)

# Task4. RLHFì™€ DeepSpeedChatì„ í†µí•œ ìµœì¢… ëª¨ë¸ êµ¬í˜„
- Microsoftì—ì„œ ë§Œë“  ëŒ€ê·œëª¨ ë¶„ì‚° ë”¥ëŸ¬ë‹ì„ ìœ„í•œ ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ ìµœì í™” ê¸°ìˆ (DeepSpeed)ì„ RLHF Processì— ì ìš©í•œ DeepSpeedChat ì‚¬ìš©
- Human preferenceë¡œ í•™ìŠµì„ ì‹œí‚¨ Reward ëª¨ë¸ê³¼ ê°•í™”í•™ìŠµì„ í†µí•´ SFT ëª¨ë¸ì— ì‚¬ëŒì˜ ì„ í˜¸ë„ë¥¼ ë°˜ì˜í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³ (FRIENDLY), ìœ¤ë¦¬ì ì¸ (HARMLESS)Â ì±—ë´‡ ìƒì„±
  
## Baseline Models
- Actor Model: KULLM-SFT-V2
- Reward Model: Polyglot-Ko-Reward-V3

## Training Options
![image](https://github.com/VAIV-2023/VAIV2023/assets/79634774/ae2cdfe5-7552-4009-a99a-244e79d945dc)

## RLHF Training
![image](https://github.com/VAIV-2023/VAIV2023/assets/79634774/3d4dbf68-5222-4f6a-a6d0-87ea176c5211)
- í•™ìŠµ ê²°ê³¼, SFT ëª¨ë¸ì˜ ë‹µë³€ì— ëŒ€í•œ í€„ë¦¬í‹°ì¸ Rewardê°€ ìƒìŠ¹í•˜ëŠ” ê²ƒì„ í™•ì¸ (ì‚¬ëŒì˜ ì„ í˜¸ë„ê°€ ë†’ì€ ë‹µë³€ì„ ìƒì„±)

## RLFH Model Evaluation
![image](https://github.com/VAIV-2023/VAIV2023/assets/79634774/2b58ed3a-7ed5-4e60-ba4b-c9b291b1fdff)
![image](https://github.com/VAIV-2023/VAIV2023/assets/79634774/75b2a1ee-d7c0-4ba9-ab2f-727abab644e9)

## Final RLHF Model
- https://huggingface.co/Trofish/KULLM-RLHF


# Contributors ğŸ™Œ 
- ë°•ì„±ì™„ (ì„±ê· ê´€ëŒ€í•™êµ ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ 20í•™ë²ˆ, waniboyy@gmail.com)
- ì†¡í˜„ë¹ˆ (ì„±ê· ê´€ëŒ€í•™êµ ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ 20í•™ë²ˆ, shbin0519@gmail.com)
- í—ˆìœ ë¯¼ (ì„±ê· ê´€ëŒ€í•™êµ ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ 21í•™ë²ˆ, ymheo1123@gmail.com)
- í™ì—¬ì› (ì„±ê· ê´€ëŒ€í•™êµ ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ 20í•™ë²ˆ, ryeowon13@gmail.com)

