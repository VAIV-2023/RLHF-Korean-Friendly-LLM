{
  "best_metric": 1.8810746669769287,
  "best_model_checkpoint": "./lora_weights/all/checkpoint-200",
  "epoch": 2.8933092224231465,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 2.9999999999999997e-06,
      "loss": 2.1365,
      "step": 1
    },
    {
      "epoch": 0.03,
      "learning_rate": 5.999999999999999e-06,
      "loss": 2.4423,
      "step": 2
    },
    {
      "epoch": 0.04,
      "learning_rate": 8.999999999999999e-06,
      "loss": 2.0946,
      "step": 3
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.1999999999999999e-05,
      "loss": 2.0345,
      "step": 4
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.4999999999999999e-05,
      "loss": 2.1751,
      "step": 5
    },
    {
      "epoch": 0.09,
      "learning_rate": 1.7999999999999997e-05,
      "loss": 2.1205,
      "step": 6
    },
    {
      "epoch": 0.1,
      "learning_rate": 2.1e-05,
      "loss": 2.3743,
      "step": 7
    },
    {
      "epoch": 0.12,
      "learning_rate": 2.3999999999999997e-05,
      "loss": 2.1659,
      "step": 8
    },
    {
      "epoch": 0.13,
      "learning_rate": 2.6999999999999996e-05,
      "loss": 2.1126,
      "step": 9
    },
    {
      "epoch": 0.14,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 1.8426,
      "step": 10
    },
    {
      "epoch": 0.16,
      "learning_rate": 3.2999999999999996e-05,
      "loss": 2.172,
      "step": 11
    },
    {
      "epoch": 0.17,
      "learning_rate": 3.5999999999999994e-05,
      "loss": 1.9969,
      "step": 12
    },
    {
      "epoch": 0.19,
      "learning_rate": 3.9e-05,
      "loss": 1.9517,
      "step": 13
    },
    {
      "epoch": 0.2,
      "learning_rate": 4.2e-05,
      "loss": 2.0468,
      "step": 14
    },
    {
      "epoch": 0.22,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 2.0802,
      "step": 15
    },
    {
      "epoch": 0.23,
      "learning_rate": 4.7999999999999994e-05,
      "loss": 2.2332,
      "step": 16
    },
    {
      "epoch": 0.25,
      "learning_rate": 5.1e-05,
      "loss": 2.1406,
      "step": 17
    },
    {
      "epoch": 0.26,
      "learning_rate": 5.399999999999999e-05,
      "loss": 2.1455,
      "step": 18
    },
    {
      "epoch": 0.27,
      "learning_rate": 5.6999999999999996e-05,
      "loss": 1.9116,
      "step": 19
    },
    {
      "epoch": 0.29,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 2.1581,
      "step": 20
    },
    {
      "epoch": 0.3,
      "learning_rate": 6.299999999999999e-05,
      "loss": 2.3653,
      "step": 21
    },
    {
      "epoch": 0.32,
      "learning_rate": 6.599999999999999e-05,
      "loss": 1.9572,
      "step": 22
    },
    {
      "epoch": 0.33,
      "learning_rate": 6.9e-05,
      "loss": 1.9621,
      "step": 23
    },
    {
      "epoch": 0.35,
      "learning_rate": 7.199999999999999e-05,
      "loss": 1.9712,
      "step": 24
    },
    {
      "epoch": 0.36,
      "learning_rate": 7.5e-05,
      "loss": 2.2864,
      "step": 25
    },
    {
      "epoch": 0.38,
      "learning_rate": 7.8e-05,
      "loss": 1.8992,
      "step": 26
    },
    {
      "epoch": 0.39,
      "learning_rate": 8.1e-05,
      "loss": 2.0248,
      "step": 27
    },
    {
      "epoch": 0.41,
      "learning_rate": 8.4e-05,
      "loss": 2.0468,
      "step": 28
    },
    {
      "epoch": 0.42,
      "learning_rate": 8.699999999999999e-05,
      "loss": 2.0098,
      "step": 29
    },
    {
      "epoch": 0.43,
      "learning_rate": 8.999999999999999e-05,
      "loss": 1.7596,
      "step": 30
    },
    {
      "epoch": 0.45,
      "learning_rate": 9.3e-05,
      "loss": 1.9968,
      "step": 31
    },
    {
      "epoch": 0.46,
      "learning_rate": 9.599999999999999e-05,
      "loss": 2.2952,
      "step": 32
    },
    {
      "epoch": 0.48,
      "learning_rate": 9.9e-05,
      "loss": 1.7345,
      "step": 33
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.000102,
      "loss": 2.2549,
      "step": 34
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00010499999999999999,
      "loss": 1.769,
      "step": 35
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00010799999999999998,
      "loss": 1.4595,
      "step": 36
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00011099999999999999,
      "loss": 1.9372,
      "step": 37
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00011399999999999999,
      "loss": 1.8464,
      "step": 38
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.000117,
      "loss": 1.8662,
      "step": 39
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00011999999999999999,
      "loss": 1.6928,
      "step": 40
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00012299999999999998,
      "loss": 1.9396,
      "step": 41
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00012599999999999997,
      "loss": 1.8354,
      "step": 42
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.000129,
      "loss": 2.0872,
      "step": 43
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00013199999999999998,
      "loss": 1.8818,
      "step": 44
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.000135,
      "loss": 1.8152,
      "step": 45
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.000138,
      "loss": 1.8045,
      "step": 46
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00014099999999999998,
      "loss": 1.8101,
      "step": 47
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00014399999999999998,
      "loss": 1.8181,
      "step": 48
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.000147,
      "loss": 1.9186,
      "step": 49
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00015,
      "loss": 1.867,
      "step": 50
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00015299999999999998,
      "loss": 1.7388,
      "step": 51
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.000156,
      "loss": 1.7917,
      "step": 52
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.000159,
      "loss": 1.7921,
      "step": 53
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.000162,
      "loss": 1.8412,
      "step": 54
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.000165,
      "loss": 2.0004,
      "step": 55
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.000168,
      "loss": 2.1484,
      "step": 56
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00017099999999999998,
      "loss": 1.9571,
      "step": 57
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00017399999999999997,
      "loss": 1.9023,
      "step": 58
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00017699999999999997,
      "loss": 1.8915,
      "step": 59
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00017999999999999998,
      "loss": 1.7747,
      "step": 60
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00018299999999999998,
      "loss": 1.9045,
      "step": 61
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.000186,
      "loss": 2.0283,
      "step": 62
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00018899999999999999,
      "loss": 1.8682,
      "step": 63
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00019199999999999998,
      "loss": 1.7368,
      "step": 64
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.000195,
      "loss": 1.9365,
      "step": 65
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.000198,
      "loss": 1.8181,
      "step": 66
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.000201,
      "loss": 1.7529,
      "step": 67
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.000204,
      "loss": 1.9785,
      "step": 68
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00020699999999999996,
      "loss": 1.7538,
      "step": 69
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.782,
      "step": 70
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00021299999999999997,
      "loss": 1.7088,
      "step": 71
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00021599999999999996,
      "loss": 1.8826,
      "step": 72
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00021899999999999998,
      "loss": 1.7538,
      "step": 73
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00022199999999999998,
      "loss": 1.8762,
      "step": 74
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.000225,
      "loss": 1.9131,
      "step": 75
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00022799999999999999,
      "loss": 1.5785,
      "step": 76
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00023099999999999998,
      "loss": 1.736,
      "step": 77
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.000234,
      "loss": 1.8947,
      "step": 78
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.000237,
      "loss": 1.7316,
      "step": 79
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00023999999999999998,
      "loss": 1.8015,
      "step": 80
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.000243,
      "loss": 1.8136,
      "step": 81
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00024599999999999996,
      "loss": 1.8223,
      "step": 82
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.000249,
      "loss": 1.7965,
      "step": 83
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00025199999999999995,
      "loss": 1.9006,
      "step": 84
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00025499999999999996,
      "loss": 1.7133,
      "step": 85
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.000258,
      "loss": 1.8099,
      "step": 86
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000261,
      "loss": 1.7695,
      "step": 87
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00026399999999999997,
      "loss": 1.9523,
      "step": 88
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.000267,
      "loss": 1.8415,
      "step": 89
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00027,
      "loss": 1.8858,
      "step": 90
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00027299999999999997,
      "loss": 1.7559,
      "step": 91
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000276,
      "loss": 1.9201,
      "step": 92
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.000279,
      "loss": 1.9143,
      "step": 93
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00028199999999999997,
      "loss": 1.4195,
      "step": 94
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.000285,
      "loss": 1.5272,
      "step": 95
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00028799999999999995,
      "loss": 1.9025,
      "step": 96
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00029099999999999997,
      "loss": 1.8889,
      "step": 97
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.000294,
      "loss": 1.5415,
      "step": 98
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00029699999999999996,
      "loss": 1.8897,
      "step": 99
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003,
      "loss": 1.6778,
      "step": 100
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00029719626168224294,
      "loss": 1.6923,
      "step": 101
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00029439252336448596,
      "loss": 2.0265,
      "step": 102
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0002915887850467289,
      "loss": 1.6772,
      "step": 103
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00028878504672897194,
      "loss": 1.8044,
      "step": 104
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0002859813084112149,
      "loss": 2.048,
      "step": 105
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0002831775700934579,
      "loss": 1.7873,
      "step": 106
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0002803738317757009,
      "loss": 1.7201,
      "step": 107
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0002775700934579439,
      "loss": 1.7781,
      "step": 108
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00027476635514018686,
      "loss": 1.9415,
      "step": 109
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0002719626168224299,
      "loss": 1.7738,
      "step": 110
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00026915887850467284,
      "loss": 1.4689,
      "step": 111
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00026635514018691586,
      "loss": 1.8439,
      "step": 112
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0002635514018691588,
      "loss": 1.7401,
      "step": 113
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00026074766355140184,
      "loss": 1.6132,
      "step": 114
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0002579439252336448,
      "loss": 1.6645,
      "step": 115
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0002551401869158878,
      "loss": 1.8285,
      "step": 116
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0002523364485981308,
      "loss": 1.602,
      "step": 117
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0002495327102803738,
      "loss": 1.8307,
      "step": 118
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00024672897196261677,
      "loss": 1.7956,
      "step": 119
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0002439252336448598,
      "loss": 1.6347,
      "step": 120
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00024112149532710278,
      "loss": 1.6127,
      "step": 121
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00023831775700934577,
      "loss": 1.5543,
      "step": 122
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00023551401869158876,
      "loss": 1.868,
      "step": 123
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00023271028037383175,
      "loss": 1.9529,
      "step": 124
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.00022990654205607474,
      "loss": 1.5753,
      "step": 125
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00022710280373831773,
      "loss": 1.6438,
      "step": 126
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00022429906542056072,
      "loss": 1.9533,
      "step": 127
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0002214953271028037,
      "loss": 1.8304,
      "step": 128
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0002186915887850467,
      "loss": 1.899,
      "step": 129
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0002158878504672897,
      "loss": 1.6453,
      "step": 130
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00021308411214953268,
      "loss": 1.6457,
      "step": 131
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00021028037383177567,
      "loss": 1.7898,
      "step": 132
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00020747663551401867,
      "loss": 1.786,
      "step": 133
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00020467289719626166,
      "loss": 1.8159,
      "step": 134
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00020186915887850465,
      "loss": 1.8114,
      "step": 135
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00019906542056074764,
      "loss": 1.6576,
      "step": 136
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00019626168224299063,
      "loss": 1.6836,
      "step": 137
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00019345794392523362,
      "loss": 1.5265,
      "step": 138
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0001906542056074766,
      "loss": 1.576,
      "step": 139
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0001878504672897196,
      "loss": 1.6933,
      "step": 140
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0001850467289719626,
      "loss": 1.7419,
      "step": 141
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.00018224299065420558,
      "loss": 1.7855,
      "step": 142
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00017943925233644857,
      "loss": 1.818,
      "step": 143
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.00017663551401869156,
      "loss": 1.7913,
      "step": 144
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.00017383177570093455,
      "loss": 1.6589,
      "step": 145
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00017102803738317754,
      "loss": 1.6474,
      "step": 146
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00016822429906542053,
      "loss": 1.483,
      "step": 147
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.00016542056074766352,
      "loss": 1.7361,
      "step": 148
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00016261682242990652,
      "loss": 1.7175,
      "step": 149
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0001598130841121495,
      "loss": 1.3909,
      "step": 150
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0001570093457943925,
      "loss": 1.7974,
      "step": 151
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0001542056074766355,
      "loss": 1.6982,
      "step": 152
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00015140186915887848,
      "loss": 1.7618,
      "step": 153
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00014859813084112147,
      "loss": 1.6139,
      "step": 154
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00014579439252336446,
      "loss": 1.5713,
      "step": 155
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00014299065420560745,
      "loss": 1.686,
      "step": 156
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00014018691588785044,
      "loss": 1.6207,
      "step": 157
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00013738317757009343,
      "loss": 1.9395,
      "step": 158
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00013457943925233642,
      "loss": 1.5759,
      "step": 159
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0001317757009345794,
      "loss": 1.8106,
      "step": 160
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0001289719626168224,
      "loss": 1.6978,
      "step": 161
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0001261682242990654,
      "loss": 1.6137,
      "step": 162
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00012336448598130838,
      "loss": 1.7105,
      "step": 163
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.00012056074766355139,
      "loss": 1.6294,
      "step": 164
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00011775700934579438,
      "loss": 1.7437,
      "step": 165
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00011495327102803737,
      "loss": 1.7189,
      "step": 166
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.00011214953271028036,
      "loss": 1.8248,
      "step": 167
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00010934579439252335,
      "loss": 1.6196,
      "step": 168
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.00010654205607476634,
      "loss": 1.947,
      "step": 169
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00010373831775700933,
      "loss": 1.6855,
      "step": 170
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.00010093457943925232,
      "loss": 1.5756,
      "step": 171
    },
    {
      "epoch": 2.49,
      "learning_rate": 9.813084112149531e-05,
      "loss": 1.729,
      "step": 172
    },
    {
      "epoch": 2.5,
      "learning_rate": 9.53271028037383e-05,
      "loss": 1.7792,
      "step": 173
    },
    {
      "epoch": 2.52,
      "learning_rate": 9.25233644859813e-05,
      "loss": 1.739,
      "step": 174
    },
    {
      "epoch": 2.53,
      "learning_rate": 8.971962616822429e-05,
      "loss": 1.6338,
      "step": 175
    },
    {
      "epoch": 2.55,
      "learning_rate": 8.691588785046728e-05,
      "loss": 1.8229,
      "step": 176
    },
    {
      "epoch": 2.56,
      "learning_rate": 8.411214953271027e-05,
      "loss": 1.6685,
      "step": 177
    },
    {
      "epoch": 2.58,
      "learning_rate": 8.130841121495326e-05,
      "loss": 1.6722,
      "step": 178
    },
    {
      "epoch": 2.59,
      "learning_rate": 7.850467289719625e-05,
      "loss": 1.4076,
      "step": 179
    },
    {
      "epoch": 2.6,
      "learning_rate": 7.570093457943924e-05,
      "loss": 1.7609,
      "step": 180
    },
    {
      "epoch": 2.62,
      "learning_rate": 7.289719626168223e-05,
      "loss": 1.865,
      "step": 181
    },
    {
      "epoch": 2.63,
      "learning_rate": 7.009345794392522e-05,
      "loss": 1.8899,
      "step": 182
    },
    {
      "epoch": 2.65,
      "learning_rate": 6.728971962616821e-05,
      "loss": 1.6128,
      "step": 183
    },
    {
      "epoch": 2.66,
      "learning_rate": 6.44859813084112e-05,
      "loss": 1.6487,
      "step": 184
    },
    {
      "epoch": 2.68,
      "learning_rate": 6.168224299065419e-05,
      "loss": 1.7253,
      "step": 185
    },
    {
      "epoch": 2.69,
      "learning_rate": 5.887850467289719e-05,
      "loss": 1.7682,
      "step": 186
    },
    {
      "epoch": 2.71,
      "learning_rate": 5.607476635514018e-05,
      "loss": 1.7673,
      "step": 187
    },
    {
      "epoch": 2.72,
      "learning_rate": 5.327102803738317e-05,
      "loss": 1.9219,
      "step": 188
    },
    {
      "epoch": 2.73,
      "learning_rate": 5.046728971962616e-05,
      "loss": 1.6323,
      "step": 189
    },
    {
      "epoch": 2.75,
      "learning_rate": 4.766355140186915e-05,
      "loss": 1.5057,
      "step": 190
    },
    {
      "epoch": 2.76,
      "learning_rate": 4.485981308411214e-05,
      "loss": 1.7274,
      "step": 191
    },
    {
      "epoch": 2.78,
      "learning_rate": 4.2056074766355134e-05,
      "loss": 1.7193,
      "step": 192
    },
    {
      "epoch": 2.79,
      "learning_rate": 3.9252336448598124e-05,
      "loss": 1.5554,
      "step": 193
    },
    {
      "epoch": 2.81,
      "learning_rate": 3.6448598130841115e-05,
      "loss": 1.7456,
      "step": 194
    },
    {
      "epoch": 2.82,
      "learning_rate": 3.3644859813084105e-05,
      "loss": 1.8456,
      "step": 195
    },
    {
      "epoch": 2.84,
      "learning_rate": 3.0841121495327096e-05,
      "loss": 1.816,
      "step": 196
    },
    {
      "epoch": 2.85,
      "learning_rate": 2.803738317757009e-05,
      "loss": 1.7411,
      "step": 197
    },
    {
      "epoch": 2.86,
      "learning_rate": 2.523364485981308e-05,
      "loss": 1.601,
      "step": 198
    },
    {
      "epoch": 2.88,
      "learning_rate": 2.242990654205607e-05,
      "loss": 1.7957,
      "step": 199
    },
    {
      "epoch": 2.89,
      "learning_rate": 1.9626168224299062e-05,
      "loss": 1.5603,
      "step": 200
    },
    {
      "epoch": 2.89,
      "eval_loss": 1.8810746669769287,
      "eval_runtime": 55.5774,
      "eval_samples_per_second": 4.498,
      "eval_steps_per_second": 0.576,
      "step": 200
    }
  ],
  "max_steps": 207,
  "num_train_epochs": 3,
  "total_flos": 2.7554377674473472e+17,
  "trial_name": null,
  "trial_params": null
}
